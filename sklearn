  sklearn
from sklearn.cross_validation import KFold
from sklearn.cross_validation import cross_val_score
admissions = pd.read_csv("admissions.csv")
admissions["actual_label"] = admissions["admit"]
admissions = admissions.drop("admit", axis=1)
kf=KFold(len(admissions),5,shuffle=True,random_state=8)
lr=LogisticRegression()
accuracies=cross_val_score(lr,admissions[["gpa"]],admissions["actual_label"],scoring='accuracy',cv=kf)
average_accuracy=np.mean(accuracies)
print(accuracies,average_accuracy)



Scoring	Function	Comment
Classification	 	 
‘accuracy’	  metrics.accuracy_score	 
‘average_precision’	  metrics.average_precision_score	 
‘f1’	  metrics.f1_score	for binary targets
‘f1_micro’	  metrics.f1_score	micro-averaged
‘f1_macro’	  metrics.f1_score	macro-averaged
‘f1_weighted’	  metrics.f1_score	weighted average
‘f1_samples’	  metrics.f1_score	by multilabel sample
‘neg_log_loss’	  metrics.log_loss	requires predict_proba support
‘precision’  etc.	metrics.precision_score	suffixes apply as with ‘f1’
‘recall’  etc.	metrics.recall_score	suffixes apply as with ‘f1’
‘roc_auc’	  metrics.roc_auc_score	 
Clustering	 	 
‘adjusted_rand_score’	  metrics.adjusted_rand_score	 
Regression	 	 
‘neg_mean_absolute_error’	  metrics.mean_absolute_error	 
‘neg_mean_squared_error’	  metrics.mean_squared_error	 
‘neg_median_absolute_error’	  metrics.median_absolute_error	 
‘r2’	  metrics.r2_score



from sklearn import svm, datasets
>>> from sklearn.model_selection import cross_val_score
>>> iris = datasets.load_iris()
>>> X, y = iris.data, iris.target
>>> clf = svm.SVC(probability=True, random_state=0)
>>> cross_val_score(clf, X, y, scoring='neg_log_loss',cv=''/k-fold or etc.) 
array([-0.07..., -0.16..., -0.06...])
>>> model = svm.SVC()
>>> cross_val_score(model, X, y, scoring='')



####important
from sklearn.cross_validation import KFold
from sklearn.metrics import mean_squared_error
import numpy as np
def train_and_cross_val(cols):
    features = filtered_cars[cols]
    target = filtered_cars["mpg"]
    
    variance_values = []
    mse_values = []
    
    # KFold instance.
    kf = KFold(n=len(filtered_cars), n_folds=10, shuffle=True, random_state=3)
    
    # Iterate through over each fold.
    for train_index, test_index in kf:
        # Training and test sets.
        X_train, X_test = features.iloc[train_index], features.iloc[test_index]
        y_train, y_test = target.iloc[train_index], target.iloc[test_index]
        
        # Fit the model and make predictions.
        lr = LinearRegression()
        lr.fit(X_train, y_train)
        predictions = lr.predict(X_test)
        
        # Calculate mse and variance values for this fold.
        mse = mean_squared_error(y_test, predictions)
        var = np.var(predictions)

        # Append to arrays to do calculate overall average mse and variance values.
        variance_values.append(var)
        mse_values.append(mse)
   
    # Compute average mse and variance values.
    avg_mse = np.mean(mse_values)
    avg_var = np.mean(variance_values)
    return(avg_mse, avg_var)
        
two_mse, two_var = train_and_cross_val(["cylinders", "displacement"])
three_mse, three_var = train_and_cross_val(["cylinders", "displacement", "horsepower"])
four_mse, four_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight"])
five_mse, five_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration"])
six_mse, six_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration", "model year"])
seven_mse, seven_var = train_and_cross_val(["cylinders", "displacement", "horsepower", "weight", "acceleration","model year", "origin"])
